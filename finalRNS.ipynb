{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cadca35-a3eb-4f25-ac04-a518ab7f454f",
   "metadata": {},
   "source": [
    "# Radius of Non-Singularity\n",
    "This code is used for calculating the radius of Non-Singularity with Quantum Logic. It follows along the Paper \"Verifying Interval Matrix properties on a quantum computer\" [Jan Schneider, Julian Berberich 2023].\n",
    "\n",
    "The considered problem is given as $ d(A,\\Delta)=\\frac{1}{\\max\\{\\rho_0(A^{-1}T_y \\Delta T_z)|y,z \\in Q_n \\}} $. We can see here that the important part is the denominator, where we have to solve a binary optimization problem. For cases like this, the Quantum Approximate Optimization Algorithm is very useful and hence is used in this code. \n",
    "\n",
    "So we give the code a problem specific $ A^{-1} $ and since we are considering the genral case also a $ \\delta $ matrix. Since the inversion of a Matrix can be done in polynomial time, it does not infect the complexity and we directly give the code an inverse. The code then calculates $ \\max\\{\\rho_0(A^{-1}T_y \\Delta T_z)|y,z \\in Q_n \\} $ and gives back the solution string with the highest amount of counts. In other words, that solution which resulted during the optimization the highest ammount of times as the optimum. Thanks to [laurgao](https://github.com/laurgao/qaoa-weighted-maxcut#some-interesting-insights) for the optimization structure and some important tips and hints.\n",
    "\n",
    "Edit: We restrained conditions on $\\Delta$ being a ranc(1) Matrix. This code works for $\\Delta=\\delta^Te$.\n",
    "\n",
    "We start by importing all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46987113-b55a-47f7-a6bb-79a0be007023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130241a6-f866-40d4-9632-afbffa7fc034",
   "metadata": {},
   "source": [
    "In the next cell we set up our initial Problem. Since the Instance to the algorithm is a Matrix, we somehow have to incorporate this to the algorithm. A very convenient fashion of working with matrices is by transforming them into bipartite graphs. The idea behind this relies on the correlation between the maxcut quantum algorithm and our problem set up. These Graphs exist of 2 distinct subsets representing our nxn space. Hence we need n vertices per subset in order to represent a nxn Matrix. Note that it would not be necessary to do this step, it is just easier to incorporate the right edges at the right places. \n",
    "\n",
    "The bipartite graph representation of a matrix is then fairly simple. The $ i,j $-th matrix entry is represented by connecting node $ i $ of the first subset with node $ j$ of the second one with a weighted edge. The edge weight represents the value of the matrix entry.\n",
    "\n",
    "What we end up with is a function to convert matrices in a bipartite graph and the setup of $ A $ and $ \\delta $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f2b846-f036-4199-826d-1d5b8770526c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 4): 1, (0, 5): 0, (0, 6): 1, (0, 7): 1, (1, 4): 1, (1, 5): 1, (1, 6): 0, (1, 7): 1, (2, 4): 0, (2, 5): 1, (2, 6): 1, (2, 7): 1, (3, 4): 1, (3, 5): 1, (3, 6): 1, (3, 7): 0}\n",
      "{(0, 4): 1, (0, 5): 1, (0, 6): 1, (0, 7): 1, (1, 4): 2, (1, 5): 2, (1, 6): 2, (1, 7): 2, (2, 4): 3, (2, 5): 3, (2, 6): 3, (2, 7): 3, (3, 4): 4, (3, 5): 4, (3, 6): 4, (3, 7): 4}\n"
     ]
    }
   ],
   "source": [
    "def convert_to_bipartite(A):\n",
    "    bip = nx.Graph()\n",
    "    n = np.sqrt(A.size).astype(int)\n",
    "    nodes_1 = list(range(0,n))\n",
    "    nodes_2 = list(range(n,2*n))\n",
    "    bip.add_nodes_from(nodes_1,bipartite=0)\n",
    "    bip.add_nodes_from(nodes_2,bipartite=1)\n",
    "    for i in range(n):\n",
    "        for j in range(n,2*n):\n",
    "            bip.add_edge(i,j,weight = A[i,j-n])\n",
    "    \n",
    "    pos = nx.bipartite_layout(bip,nodes_1)\n",
    "    return bip,pos\n",
    "\n",
    "#define Graph\n",
    "#A_m2 = np.array([[1,2,3,4],[3,4,1,2],[2,3,4,1],[4,1,2,3]])\n",
    "A_m2 = np.array([[1,0,1,1],[1,1,0,1],[0,1,1,1],[1,1,1,0]])\n",
    "G,pos = convert_to_bipartite(A_m2)\n",
    "dimension = np.sqrt(A_m2.size).astype(int) #matrix dimension\n",
    "\n",
    "edges = list(G.edges())\n",
    "weighted_edges = nx.get_edge_attributes(G, 'weight')\n",
    "#print(weighted_edges)#printing the edges and the according weights (matrix entrys)\n",
    "\n",
    "#define uncertainty\n",
    "Delta = np.array([[1,1,1,1],[2,2,2,2],[3,3,3,3],[4,4,4,4]])\n",
    "G_D,pos_D = convert_to_bipartite(Delta)\n",
    "\n",
    "edges_D = list(G_D.edges())\n",
    "weighted_edges_D = nx.get_edge_attributes(G_D, 'weight')\n",
    "#print(weighted_edges_D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b27f8-7804-4099-8c32-9c5dcddc72f3",
   "metadata": {},
   "source": [
    "Next, we have to initialize the necessary things for the QAOA algorithm. QAOAs working principle is applying a problem unitary $ U(\\gamma) $ and a mixing unitary $ U(\\beta) $ alternating a certain ammount of times on an initial quantum state in super position. Then the expactation value is evaluated and the both variables $ \\gamma $ and $ \\beta $ are optimized. In every iteration, we end up with an evaluation that results in a solution string for the current optimum. This is how a solution string receives a count in the histogram.\n",
    "\n",
    "We start of with the simulation parameters: \n",
    "* num_layers indicates how often we apply both unitaries. A low natural number is usually a good trade off between comlexity and efficiency. \n",
    "* n_qbits are double the ammount of the matrix dimension due to the problem set up.\n",
    "* n_iterations defines the amount of optimization repititions. Note that this has to be choosen according to the problem dimension. For low dimensional problems, 100 iterations are sufficient. But considering for example already a 4x4 matrix, we end up with $ 2^8 $ different solutions. If we split up 100 counts on 256 solutions, it is possible that the real optimum blends in with the wrong solutions too much. However, keep in mind that more iterations increase the computational complexity.\n",
    "* num_reps defines the amount of repeated algorithm iteration. Remember, that the algorithm is optimizing iteratively whil at every iteration, the algorithm is applied num_reps times\n",
    "\n",
    "After that we construct the problem hamiltonian with the combination of $ CNOT $, $ RZ $ and $ CNOT $ as explained in the paper, depending on the individual qubits which are connected. The edge weight is then multiplied on the optimization variables. \n",
    "\n",
    "The mixing hamiltonian can be choosen by some beforehand given approach, which result in exploring the solution state between the layers.\n",
    "\n",
    "The last function is used to measure the expactation value in the correct computational basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f5a556a-ac7f-4b8a-8d6f-39a45b569218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setup all the initial values for QAOA and the fundamental hamiltonians\n",
    "num_layers = 4 #numbers of alternating mixing and problem hamiltonians\n",
    "n_qbits = 2*dimension #need double the amount of qubits for algorithm\n",
    "n_iterations = 100\n",
    "init_params = 0.01 * np.random.rand(2, num_layers) # Initialize the parameters near zero. Generates array size 2, 4. \n",
    "num_iters = 100\n",
    "num_reps =100\n",
    "        \n",
    "def algorithm_unitary(gamma,beta):\n",
    "    #cost hamiltonian\n",
    "    for edge in edges:  # pairs of nodes\n",
    "        #due to the representation as bipartite, the qubits are seperated in 2 sets \n",
    "        #and the cost hamiltonian is formulated similar to the maxcut\n",
    "        wire1 = edge[0]\n",
    "        wire2 = edge[1]\n",
    "        \n",
    "        weight_A = weighted_edges[edge]\n",
    "        weight_Delta = weighted_edges_D[edge] #new imposed weight from uncertainty description\n",
    "        weight = weight_A*weight_Delta\n",
    "        #Not that the gate we wanna use hear is a controlled Z gate (RZZ). However, \n",
    "        #it qml doesnt provide this feature so we buil it on our own\n",
    "        qml.CNOT(wires=[wire1, wire2])\n",
    "        qml.RZ(weight*gamma, wires=wire2) #Major change to maxcut, we incorporate the weight into the optimization\n",
    "        qml.CNOT(wires=[wire1, wire2])\n",
    "    \n",
    "    #mixing_hamiltonian\n",
    "    for wire in range(n_qbits):\n",
    "        qml.RX(2 * beta, wires=wire)\n",
    "        \n",
    "# Defining a function to measure all qubits in the computational basis, because Pennylane doesn't seem to have one.\n",
    "def comp_basis_measurement(wires):\n",
    "    n_qbits = len(wires)\n",
    "    return qml.Hermitian(np.diag(range(2 ** n_qbits)), wires=wires)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70385740-cad5-493d-a170-e953f06437d0",
   "metadata": {},
   "source": [
    "The next cell inhibits just some necessary transition functions to switch between decimal and binary numbers and extracting binary strings out of bit strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3efc6492-bc37-481a-aa73-6a576903e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#important functions for calculating different transformatins\n",
    "def get_binary_bit_strings(bit_strings):\n",
    "    bit_strings_binary = []\n",
    "    for bit in bit_strings:  # Loops through each of the 100 measurements\n",
    "        bit_strings_binary.append(decimal_to_binary(bit))\n",
    "    return bit_strings_binary\n",
    "\n",
    "def decimal_to_binary(decimal): # future: abstract this function to take in length.\n",
    "    binary_num = []\n",
    "    \n",
    "    # Outputs bitstring of 1s and 0s into an array of digits\n",
    "    def convert(decimal):\n",
    "        if decimal >= 1:\n",
    "            convert(decimal // 2)\n",
    "            binary_num.append(decimal % 2)\n",
    "    \n",
    "    convert(decimal)\n",
    "            \n",
    "        \n",
    "    # Change the binary number to have 4 digits, if it doesn't already\n",
    "    for i in range(n_qbits + 1):\n",
    "        if len(binary_num) < i:\n",
    "            binary_num.insert(0, 0) # At beginning append 0\n",
    "    \n",
    "    return binary_num # Outputs array of the digits of the binary number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303487f3-af28-44f1-a45b-98258de541c8",
   "metadata": {},
   "source": [
    "Now we construct the algorithm by concatenating all important parts, and define a function to read out the counts of the algorithm. To run the algorithm successfully, the last missing component is an appropriate cost function. The definition for the cost is also given analog to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e51f9cb7-0f30-4817-b0ba-a716e38b193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Up Quantum Device and Algorithm\n",
    "dev = qml.device(\"default.qubit\", wires=n_qbits, shots=1)\n",
    "@qml.qnode(dev)\n",
    "\n",
    "def circuit(gammas, betas, num_layers = 1):\n",
    "    # Applies a Hadamard gate to each qubit, which puts our circuit into the quantum state |+...+>\n",
    "    # In this state, the probability of measuring any computational basis state is equal. Algorithms are commonly initialized with all states in equal superposition.\n",
    "    for wire in range(n_qbits):\n",
    "        qml.Hadamard(wires=wire)\n",
    "        \n",
    "    # Repeat the cost and mixer layers p times each\n",
    "    for layer in range(num_layers):\n",
    "        algorithm_unitary(gammas[layer],betas[layer])\n",
    "        \n",
    "    # Take the measurement of all qubits in the computational basis\n",
    "    measurement = qml.sample(comp_basis_measurement(range(n_qbits)))\n",
    "    return measurement \n",
    "\n",
    "def get_counts(params):       \n",
    "    # Determine the length of the params list\n",
    "    params_length = len(params)\n",
    "\n",
    "    # Calculate the number of elements in each list (gammas and betas)\n",
    "    num_elements = params_length // 2\n",
    "\n",
    "    # Use list comprehension to create gammas and betas lists\n",
    "    gammas = [params[i] for i in range(0, params_length, 2)]\n",
    "    betas = [params[i] for i in range(1, params_length, 2)]\n",
    "    \n",
    "    # The results (bit strings) of running the circuit 100 times and getting 100 measurements\n",
    "    bit_strings = []\n",
    "    for i in range(0, num_reps):\n",
    "        hold = int(circuit(gammas, betas, num_layers=num_layers))\n",
    "        bit_strings.append(hold) # This appends the integer from 0-15 (if 4 nodes) so it outputs the computational basis measurement in decimal. \n",
    "\n",
    "    counts = np.bincount(np.array(bit_strings)) # A 1x16 array that shows the frequency of each bitstring output\n",
    "    most_freq_bit_string = np.argmax(counts) # Finds the most frequent bitstring\n",
    "\n",
    "    return counts, bit_strings, most_freq_bit_string\n",
    "\n",
    "def cost_function(params):\n",
    "    bit_strings = get_counts(params)[1]\n",
    "    binary_bit_strings = get_binary_bit_strings(bit_strings)\n",
    "    total_cost = 0\n",
    "    for i in range(0, len(binary_bit_strings)): # Length of binary_bit_strings should be 100\n",
    "        for edge in edges:\n",
    "            start_node = edge[0]\n",
    "            end_node = edge[1]\n",
    "            weight = weighted_edges[edge]*weighted_edges_D[edge]\n",
    "            \n",
    "            #this is my adaption to the cost function, see the proof for the math behind\n",
    "            ron_cost = -1*weight*binary_bit_strings[i][start_node]*binary_bit_strings[i][end_node]\n",
    "            \n",
    "            #total_cost += ron_cost\n",
    "            total_cost += ron_cost\n",
    "        \n",
    "    \n",
    "    total_cost = float(total_cost) / 100\n",
    "\n",
    "    print(\"Cost: \"+str(total_cost))\n",
    "\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a2500-1903-4760-b6bc-dcfe7df0826f",
   "metadata": {},
   "source": [
    "Last step is to run the algorithm, and print the current cost at the current iteration. This is a good indication of the performance of the algorithm. It should decrease partly and should also reach negative values. Otherwise the solution will not be good. This could have different causes like the iniitial conditions. Sometime the algorithm gets stuck in local minima which is a known problem when doing gradient descent based methods. This is why it makes sense to set random initial values for the optimization parameters, such that there is a chance to avaoid the same local minima in a second run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a078d2da-7f0c-4ddd-b878-a506684315d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7m/mqkfpjl97fv2sybjq8l1qv3r0000gn/T/ipykernel_88935/1181508760.py:5: DeprecationWarning: Use of `minimize` with `x0.ndim != 1` is deprecated. Currently, singleton dimensions will be removed from `x0`, but an error will be raised in SciPy 1.11.0.\n",
      "  out = minimize(cost_function, x0=params, method=\"COBYLA\", options={'maxiter':num_iters})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: -8.46\n",
      "Cost: -8.24\n",
      "Cost: -7.17\n",
      "Cost: -7.29\n",
      "Cost: -6.55\n",
      "Cost: -8.04\n",
      "Cost: -7.48\n",
      "Cost: -6.89\n",
      "Cost: -7.2\n",
      "Cost: -8.9\n",
      "Cost: -8.06\n",
      "Cost: -7.57\n",
      "Cost: -5.74\n",
      "Cost: -9.01\n",
      "Cost: -9.17\n",
      "Cost: -7.69\n",
      "Cost: -8.47\n",
      "Cost: -10.81\n",
      "Cost: -7.94\n",
      "Cost: -10.02\n",
      "Cost: -4.68\n",
      "Cost: -9.27\n",
      "Cost: -9.42\n",
      "Cost: -6.05\n",
      "Cost: -8.65\n",
      "Cost: -7.0\n",
      "Cost: -10.88\n",
      "Cost: -8.96\n",
      "Cost: -10.81\n",
      "Cost: -7.64\n",
      "Cost: -8.55\n",
      "Cost: -7.58\n",
      "Cost: -9.66\n",
      "Cost: -9.23\n",
      "Cost: -7.63\n",
      "Cost: -10.04\n",
      "Cost: -10.45\n",
      "Cost: -10.14\n",
      "Cost: -12.01\n",
      "Cost: -9.4\n",
      "Cost: -9.1\n",
      "Cost: -9.14\n",
      "Cost: -7.87\n",
      "Cost: -9.1\n",
      "Cost: -8.41\n",
      "Cost: -11.19\n",
      "Cost: -7.43\n",
      "Cost: -8.83\n",
      "Cost: -8.79\n",
      "Cost: -10.08\n",
      "Cost: -9.52\n",
      "Cost: -9.54\n",
      "Cost: -8.69\n",
      "Cost: -9.59\n",
      "Cost: -8.74\n",
      "Cost: -7.14\n",
      "Cost: -9.14\n",
      "Cost: -10.74\n",
      "Cost: -9.42\n",
      "Cost: -7.94\n",
      "Cost: -10.53\n",
      "Cost: -9.06\n",
      "Cost: -9.17\n",
      "Cost: -10.41\n",
      "Cost: -9.3\n",
      "Cost: -11.85\n",
      "Cost: -9.83\n",
      "Cost: -11.25\n",
      "Cost: -10.83\n",
      "Cost: -11.86\n",
      "Cost: -10.23\n",
      "Cost: -9.98\n",
      "Cost: -11.57\n",
      "Cost: -9.93\n",
      "Cost: -8.99\n",
      "Cost: -9.2\n",
      "Cost: -11.46\n",
      "Cost: -9.64\n",
      "Cost: -8.83\n",
      "Cost: -8.22\n",
      "Cost: -9.64\n",
      "Cost: -8.11\n",
      "Cost: -8.78\n",
      "Cost: -8.62\n",
      "Output result: 00000000\n"
     ]
    }
   ],
   "source": [
    "#optimzation block\n",
    "params = init_params\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "out = minimize(cost_function, x0=params, method=\"COBYLA\", options={'maxiter':num_iters}) \n",
    "# This optimizer changes our initialized params from a 2x4 array into a 1x8 array\n",
    "\n",
    "print(f'Out: {out}')\n",
    "\n",
    "optimal_params = out['x'] # This outputs a 2x4 array not a 1x8 \n",
    "optimal_params_vector = []\n",
    "for layer in range(len(optimal_params[0])): # Convert the 1x8 array into a 2x4 array\n",
    "    optimal_params_vector.append(optimal_params[0][layer])\n",
    "    optimal_params_vector.append(optimal_params[1][layer]) # optimal_params_vector is good\n",
    "    \n",
    "# optimal_params_vector is an array not a tensor \n",
    "final_bitstring = get_counts(optimal_params_vector)\n",
    "\n",
    "# The most frequent bitstring is stored in final_bitstring[2]\n",
    "binary_bit_string = ''\n",
    "for bit in decimal_to_binary(final_bitstring[2]): # This for loop gets the string version of the array binary bit string.\n",
    "        binary_bit_string += str(bit)\n",
    "\n",
    "print(f'Output result: {binary_bit_string}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c39b54-22ba-4161-a0c0-92c3c91a179a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_bitstring' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#print(final_bitstring[1])\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#print(binary_list(15,width=4))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m x_value \u001b[38;5;241m=\u001b[39m binary_list(\u001b[38;5;241m255\u001b[39m,width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m y_value \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_bitstring\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_value)\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mbar(x_value,y_value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_bitstring' is not defined"
     ]
    }
   ],
   "source": [
    "#plot histogram\n",
    "def binary_list(n, width=None):\n",
    "    #Returns a list of binary numbers up to n, with each binary number having the same width.\n",
    "    binary = []\n",
    "    for i in range(n+1):\n",
    "        binary_number = bin(i)[2:]\n",
    "        if width is not None:\n",
    "            binary_number = binary_number.zfill(width)\n",
    "        binary.append(binary_number)\n",
    "    return binary\n",
    "\n",
    "#print(final_bitstring[1])\n",
    "#print(binary_list(15,width=4))\n",
    "x_value = binary_list(255,width=4)\n",
    "y_value = final_bitstring[0]\n",
    "#print(y_value)\n",
    "plt.bar(x_value,y_value)\n",
    "plt.xticks(x_value, rotation='vertical')\n",
    "plt.ylabel(\"Counts\")\n",
    "#plt.show()\n",
    "plt.savefig('filename.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab75b9-79fe-480f-bd9e-b833dac5032d",
   "metadata": {},
   "source": [
    "The Last Cell can be used to extract the 5 largest elements and corresponding indiced,\n",
    "which is usefull for higher dimensional problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb702914-2165-495f-9120-2fe2b5c83e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "5 Largest Elements: [ 3  4  5 12 17]\n",
      "Corresponding Indices: [  4 251 128   0 255]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Your array\n",
    "array = y_value\n",
    "\n",
    "# Find the indices that would sort the array\n",
    "sorted_indices = np.argsort(array)\n",
    "print(sorted_indices.size)\n",
    "\n",
    "# Get the 5 largest elements and their indices\n",
    "largest_elements = array[sorted_indices[-5:]]\n",
    "largest_indices = sorted_indices[-5:]\n",
    "\n",
    "print(\"5 Largest Elements:\", largest_elements)\n",
    "print(\"Corresponding Indices:\", largest_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b815995-e12b-4e68-b877-144a7417680c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
